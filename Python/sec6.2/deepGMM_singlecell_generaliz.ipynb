{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "\n",
    "from scenarios.abstract_scenario import AbstractScenario\n",
    "from methods.toy_model_selection_method import ToyModelSelectionMethod # change input dimension! (f model(s) for X, g model for Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset in the same way as HSIC-X\n",
    "dataset_rpe1 = pd.read_csv(\"R/sec6.2/dataset_rpe1.csv\")\n",
    "\n",
    "# Select relevant columns (same as HSIC-X)\n",
    "interv_genes = dataset_rpe1.columns[:9].tolist()\n",
    "train_data = dataset_rpe1[dataset_rpe1['interventions'].isin(interv_genes + [\"non-targeting\"])].copy()\n",
    "\n",
    "# Convert intervention column to categorical\n",
    "train_data['interventions'] = train_data['interventions'].astype('category')\n",
    "train_data['Ztr'] = train_data.iloc[:, 10].astype('category')\n",
    "\n",
    "# Get list of unique interventions (excluding \"non-targeting\")\n",
    "unique_interventions = [g for g in train_data['interventions'].unique() if g != \"non-targeting\"]\n",
    "\n",
    "# Define test data (same as HSIC-X)\n",
    "test_data_path = 'R/sec6.2/test_single_cell.csv'\n",
    "test_data = torch.tensor(np.genfromtxt(test_data_path, delimiter=',', skip_header=1), dtype=torch.float32)\n",
    "Xtest = test_data[:, 0:9].reshape(-1, 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert `Ztr` to One-Hot Encoding AFTER removing one environment\n",
    "encoder = OneHotEncoder(sparse_output=False)  # Drop first category for consistency\n",
    "Ztr_encoded = encoder.fit_transform(train_data[['Ztr']])\n",
    "\n",
    "# Extract features and target\n",
    "Xtr = train_data.iloc[:, :9].values  # First 9 columns\n",
    "Ytr = train_data.iloc[:, 9].values   # 10th column\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "X_train = torch.tensor(Xtr, dtype=torch.float32)\n",
    "Y_train = torch.tensor(Ytr.reshape(-1, 1), dtype=torch.float32)\n",
    "Z_train = torch.tensor(Ztr_encoded, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define PyTorch Dataset\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, X, Z, Y):\n",
    "        self.X = X\n",
    "        self.Z = Z\n",
    "        self.Y = Y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.Z[idx], self.Y[idx]\n",
    "\n",
    "# Create dataset and split into training/validation sets\n",
    "dataset = MyDataset(X_train, Z_train, Y_train)\n",
    "train_ratio = 0.9\n",
    "train_size = int(train_ratio * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "\n",
    "train_data, val_data = torch.utils.data.random_split(dataset, [train_size, val_size])\n",
    "\n",
    "# Extract separate tensors for training and validation\n",
    "X_train, Z_train, Y_train = train_data.dataset.X[:train_size], train_data.dataset.Z[:train_size], train_data.dataset.Y[:train_size]\n",
    "X_val, Z_val, Y_val = val_data.dataset.X[train_size:], val_data.dataset.Z[train_size:], val_data.dataset.Y[train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to train and predict DeepGMM for a single run\n",
    "def tr_deepGMM(run_id):\n",
    "    print(f\"Starting DeepGMM Run {run_id + 1}/10...\")\n",
    "\n",
    "    # Initialize and train DeepGMM model\n",
    "    deepGMM = ToyModelSelectionMethod()\n",
    "    deepGMM.fit(X_train.double(), Z_train.double(), Y_train.double(), \n",
    "                X_val.double(), Z_val.double(), Y_val.double(), \n",
    "                g_dev=None, verbose=True)\n",
    "\n",
    "    # Predict on test data\n",
    "    y_hat_deepGMM = deepGMM.predict(Xtest.double()).flatten().detach().numpy()\n",
    "    return y_hat_deepGMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_repeats = 10\n",
    "results = Parallel(n_jobs=num_repeats)(\n",
    "    delayed(tr_deepGMM)(i) for i in range(num_repeats)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = pd.DataFrame(results).T  # Transpose to have runs as columns\n",
    "df_results.columns = [f'Run_{i+1}' for i in range(num_repeats)]\n",
    "output_filename = 'results/deepgmm_singlecell_10runs.csv'\n",
    "df_results.to_csv(output_filename, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
