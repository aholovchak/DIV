{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IS NOT USED DUE TO NAs IN THE RESULTS!\n",
    "\n",
    "from econml.iv.nnet import DeepIV\n",
    "\n",
    "import keras\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "dataset_rpe1 = pd.read_csv(\"data/sec6.2/data/dataset_rpe1.csv\")\n",
    "\n",
    "# Select relevant columns\n",
    "interv_genes = dataset_rpe1.columns[:9].tolist()\n",
    "train_data = dataset_rpe1[dataset_rpe1['interventions'].isin(interv_genes + [\"non-targeting\"])].copy()\n",
    "\n",
    "# Convert intervention column to categorical\n",
    "train_data['interventions'] = train_data['interventions'].astype('category')\n",
    "train_data['Ztr'] = train_data.iloc[:, 10].astype('category')\n",
    "\n",
    "# Get list of unique interventions (excluding \"non-targeting\")\n",
    "unique_interventions = [g for g in train_data['interventions'].unique() if g != \"non-targeting\"]\n",
    "\n",
    "# Define test data (from 50 test environments)\n",
    "test_data_path = 'data/sec6.2/test_single_cell.csv'\n",
    "test_data = pd.read_csv(test_data_path)\n",
    "Xtest = test_data.iloc[:, 0:9].values  # Extract first 9 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define treatment model (unchanged)\n",
    "def build_treatment_model():\n",
    "    return keras.Sequential([\n",
    "        keras.layers.Dense(256, activation='relu', input_shape=(10,)),\n",
    "        keras.layers.Dropout(0.17),\n",
    "        keras.layers.Dense(128, activation='relu'),\n",
    "        keras.layers.Dropout(0.17),\n",
    "        keras.layers.Dense(64, activation='relu'),\n",
    "        keras.layers.Dropout(0.17),\n",
    "        keras.layers.Dense(32, activation='relu'),\n",
    "        keras.layers.Dropout(0.17)\n",
    "    ])\n",
    "\n",
    "# Define response model (unchanged)\n",
    "def build_response_model():\n",
    "    return keras.Sequential([\n",
    "        keras.layers.Dense(256, activation='relu', input_shape=(10,)),\n",
    "        keras.layers.Dropout(0.17),\n",
    "        keras.layers.Dense(128, activation='relu'),\n",
    "        keras.layers.Dropout(0.17),\n",
    "        keras.layers.Dense(64, activation='relu'),\n",
    "        keras.layers.Dropout(0.17),\n",
    "        keras.layers.Dense(32, activation='relu'),\n",
    "        keras.layers.Dropout(0.17),\n",
    "        keras.layers.Dense(1)\n",
    "    ])\n",
    "\n",
    "keras_fit_options = { \"epochs\": 30,\n",
    "                      \"validation_split\": 0.2,\n",
    "                      \"callbacks\": [keras.callbacks.EarlyStopping(patience=2, restore_best_weights=True)]}\n",
    "\n",
    "# Define function to train DeepIV with one intervention removed\n",
    "def train_deepIV_pairwise(i, gene_to_remove):\n",
    "    print(f\"Iteration {i+1}: Removing intervention {gene_to_remove}\")\n",
    "\n",
    "    # Remove data for the given intervention\n",
    "    valid_rows = train_data['interventions'].isin([\"non-targeting\"] + list(set(interv_genes) - {gene_to_remove}))\n",
    "    filtered_data = train_data[valid_rows]\n",
    "\n",
    "    # Convert `Ztr` to One-Hot Encoding AFTER removing one environment\n",
    "    encoder = OneHotEncoder(sparse_output=False)\n",
    "    Ztr_encoded = encoder.fit_transform(filtered_data[['Ztr']])\n",
    "\n",
    "    # Extract features and target\n",
    "    Xtr = filtered_data.iloc[:, :9].values  # First 9 columns\n",
    "    Ytr = filtered_data.iloc[:, 9].values   # 10th column\n",
    "\n",
    "    z = Ztr_encoded  # Encoded intervention variable\n",
    "    t = Xtr          # First 9 columns (gene expressions)\n",
    "    y = Ytr          # 10th column (response variable)\n",
    "    x = np.zeros(Xtr.shape[0])  # Dummy placeholder if needed for consistency\n",
    "\n",
    "    # Instantiate models (exact same architecture)\n",
    "    treatment_model = build_treatment_model()\n",
    "    response_model = build_response_model()\n",
    "\n",
    "    # Define DeepIV estimator\n",
    "    deepIvEst = DeepIV(\n",
    "        n_components=10,  # Gaussian components in MDN\n",
    "        m = lambda z, x : treatment_model(keras.layers.concatenate([z,x])), # treatment model\n",
    "        h = lambda t, x : response_model(keras.layers.concatenate([t,x])),  # response model\n",
    "        n_samples=10,  # More samples for better response estimation\n",
    "        use_upper_bound_loss=False,  # Approximation to true loss\n",
    "        n_gradient_samples=5,  # More gradient samples to reduce variance\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=0.0001), # Keras optimizer to use for training - see https://keras.io/optimizers/ \n",
    "        first_stage_options=keras_fit_options,\n",
    "        second_stage_options=keras_fit_options\n",
    "    )\n",
    "\n",
    "    # Train DeepIV\n",
    "    deepIvEst.fit(Y=y,T=t,X=x,Z=z)\n",
    "    \n",
    "    # Make predictions on test data\n",
    "    y_hat_deepIV = deepIvEst.predict(Xtest, np.zeros(Xtest.shape[0]))\n",
    "\n",
    "    return i, y_hat_deepIV  # Return index and predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the 9 iterations in parallel\n",
    "if __name__ == \"__main__\":\n",
    "    num_iterations = len(unique_interventions)\n",
    "\n",
    "    results = Parallel(n_jobs=9)(\n",
    "        delayed(train_deepIV_pairwise)(i, gene_to_remove)\n",
    "        for i, gene_to_remove in enumerate(unique_interventions)\n",
    "    )\n",
    "\n",
    "    # Store predictions in DataFrame\n",
    "    df_results = pd.DataFrame({f'Run_{i+1}': y_hat_deepIV.flatten() for i, y_hat_deepIV in results})\n",
    "\n",
    "    df_results.columns = unique_interventions\n",
    "\n",
    "    # Save results\n",
    "    df_results.to_csv(\"results/sec6.2/deepiv_singlecell_pairwise.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepIV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
