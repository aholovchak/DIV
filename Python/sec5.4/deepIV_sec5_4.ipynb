{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from econml.iv.nnet import DeepIV\n",
    "import torch\n",
    "\n",
    "import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_values = [0, 1, 5]\n",
    "runs = 10  # Number of runs for each alpha value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "treatment_model = keras.Sequential([keras.layers.Dense(256, activation='relu', input_shape=(2,)),\n",
    "                                    keras.layers.Dropout(0.17),\n",
    "                                    keras.layers.Dense(128, activation='relu'),\n",
    "                                    keras.layers.Dropout(0.17),\n",
    "                                    keras.layers.Dense(64, activation='relu'),\n",
    "                                    keras.layers.Dropout(0.17),\n",
    "                                    keras.layers.Dense(32, activation='relu'),\n",
    "                                    keras.layers.Dropout(0.17)])\n",
    "\n",
    "response_model = keras.Sequential([keras.layers.Dense(256, activation='relu', input_shape=(2,)),\n",
    "                                   keras.layers.Dropout(0.17),\n",
    "                                   keras.layers.Dense(128, activation='relu'),\n",
    "                                   keras.layers.Dropout(0.17),\n",
    "                                   keras.layers.Dense(64, activation='relu'),\n",
    "                                   keras.layers.Dropout(0.17),\n",
    "                                   keras.layers.Dense(32, activation='relu'),\n",
    "                                   keras.layers.Dropout(0.17),\n",
    "                                   keras.layers.Dense(1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_fit_options = { \"epochs\": 30,\n",
    "                      \"validation_split\": 0.2,\n",
    "                      \"callbacks\": [keras.callbacks.EarlyStopping(patience=2, restore_best_weights=True)]}\n",
    "\n",
    "deepIvEst = DeepIV(n_components = 10, # number of gaussians in our mixture density network\n",
    "                   m = lambda z, x : treatment_model(keras.layers.concatenate([z,x])), # treatment model\n",
    "                   h = lambda t, x : response_model(keras.layers.concatenate([t,x])),  # response model\n",
    "                   n_samples = 1, # number of samples to use to estimate the response\n",
    "                   use_upper_bound_loss = False, # whether to use an approximation to the true loss\n",
    "                   n_gradient_samples = 1, # number of samples to use in second estimate of the response (to make loss estimate unbiased)\n",
    "                   optimizer='adam', # Keras optimizer to use for training - see https://keras.io/optimizers/ \n",
    "                   first_stage_options = keras_fit_options, # options for training treatment model\n",
    "                   second_stage_options = keras_fit_options) # options for training response model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for alpha in alpha_values:\n",
    "    train_data_path = f'data/sec5.4/train_Zcont_g_fct_f_softplusalpha{alpha}.csv'\n",
    "    test_data_path = f'data/sec5.4/test_Zcont_g_fct_f_softplusalpha{alpha}.csv'\n",
    "    \n",
    "    train_data = np.genfromtxt(train_data_path, delimiter=',', skip_header=1)\n",
    "    test_data = np.genfromtxt(test_data_path, delimiter=',', skip_header=1)\n",
    "    \n",
    "    data_length = train_data.shape[0]\n",
    "\n",
    "    # Separate the columns into individual tensors\n",
    "    z = train_data[:, 0]\n",
    "    t = train_data[:, 1]\n",
    "    y = train_data[:, 2]\n",
    "    x = np.zeros(data_length)\n",
    "    \n",
    "    X_test = torch.tensor(test_data[:,0].astype(np.float32)).squeeze()\n",
    "    #X_test_grid = torch.tensor(test_data[:,2].astype(np.float32)).squeeze()\n",
    "\n",
    "    df_mse = pd.DataFrame()\n",
    "    #df_plot = pd.DataFrame()\n",
    "    \n",
    "    for run in range(runs):\n",
    "        # Fit the DeepIV model\n",
    "        deepIvEst.fit(Y=y, T=t, X=x, Z=z)\n",
    "        \n",
    "        # Generate predictions for each x_temp\n",
    "        for i, x_temp in enumerate([x[0]]):\n",
    "            y_hat_deepiv = deepIvEst.predict(X_test, np.full_like(X_test, x_temp))\n",
    "            #y_hat_deepiv_grid = deepIvEst.predict(X_test_grid, np.full_like(X_test_grid, x_temp))\n",
    "\n",
    "        # Add the predictions as a new column to the DataFrame\n",
    "        df_mse[f'Run_{run+1}'] = y_hat_deepiv\n",
    "        #df_plot[f'Run_{run+1}'] = y_hat_deepiv_grid\n",
    "        \n",
    "    # Save the results for the current alpha\n",
    "    df_mse.to_csv(f'results/sec5.4/deepiv_result_mse_alpha{alpha}.csv', index=False)\n",
    "    #df_plot.to_csv(f'results/deepiv_result_plot_alpha{alpha}.csv', index=False)\n",
    "    \n",
    "    # Optionally, plot the results\n",
    "    # plt.scatter(X_test_grid, df_plot.iloc[:, -1], s=1, color='red', label=f'DeepIV Alpha {alpha}')\n",
    "    # plt.scatter(X_test_grid, test_data[:, 3], s=1)\n",
    "    # plt.legend()\n",
    "    # plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepIV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
