{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from methods.toy_model_selection_method import ToyModelSelectionMethod\n",
    "\n",
    "# Paths to the 10 training and testing datasets\n",
    "train_files = [\n",
    "    'data/sec5.1/train_Zbin_g_lin_f_lin.csv',\n",
    "    'data/sec5.1/train_Zcont_g_lin_f_lin.csv',\n",
    "    'data/sec5.1/train_Zbin_g_lin_f_log_case.csv',\n",
    "    'data/sec5.1/train_Zcont_g_lin_f_log_case.csv',\n",
    "    'data/sec5.1/train_Zbin_g_lin_f_sin_lin.csv',\n",
    "    'data/sec5.1/train_Zcont_g_lin_f_sin_lin.csv'\n",
    "]\n",
    "\n",
    "test_files = [\n",
    "    'data/sec5.1/test_Zbin_g_lin_f_lin.csv',\n",
    "    'data/sec5.1/test_Zcont_g_lin_f_lin.csv',\n",
    "    'data/sec5.1/test_Zbin_g_lin_f_log_case.csv',\n",
    "    'data/sec5.1/test_Zcont_g_lin_f_log_case.csv',\n",
    "    'data/sec5.1/test_Zbin_g_lin_f_sin_lin.csv',\n",
    "    'data/sec5.1/test_Zcont_g_lin_f_sin_lin.csv'\n",
    "]\n",
    "\n",
    "# Define the dataset\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]\n",
    "\n",
    "# Function to be parallelized\n",
    "def fit_predict_deepGMM(run, X_train, Z_train, Y_train, X_val, Z_val, Y_val, X_test, X_test_grid):\n",
    "    # Initialize the deepGMM model\n",
    "    deepGMM = ToyModelSelectionMethod()\n",
    "\n",
    "    # Fit the model\n",
    "    deepGMM.fit(X_train.double(), Z_train.double(), Y_train.double(),\n",
    "                X_val.double(), Z_val.double(), Y_val.double(),\n",
    "                g_dev=None, verbose=True)\n",
    "\n",
    "    # Predict\n",
    "    y_hat_deepGMM = deepGMM.predict(X_test.double()).flatten().detach().numpy()\n",
    "    y_hat_deepGMM_grid = deepGMM.predict(X_test_grid.double()).flatten().detach().numpy()\n",
    "\n",
    "    # Return predictions\n",
    "    return y_hat_deepGMM, y_hat_deepGMM_grid\n",
    "\n",
    "# Loop through all datasets\n",
    "# for idx, (train_file, test_file) in enumerate(zip(train_files, test_files), start=1):\n",
    "for idx, (train_file, test_file) in enumerate(zip(train_files[4:], test_files[4:]), start=5):\n",
    "    # Load train and test data\n",
    "    train_data = torch.tensor(np.genfromtxt(train_file, delimiter=',', skip_header=1), dtype=torch.float32)\n",
    "    test_data = np.genfromtxt(test_file, delimiter=',', skip_header=1)\n",
    "\n",
    "    data_train_length = train_data.shape[0]\n",
    "    print(f'Train data size for DGP{idx}: {data_train_length}')\n",
    "\n",
    "    # Separate the columns into individual tensors\n",
    "    Z = train_data[:, 1].reshape(-1, 1)\n",
    "    X = train_data[:, 2].reshape(-1, 1)\n",
    "    Y = train_data[:, 3].reshape(-1, 1)\n",
    "\n",
    "    # Create an instance of the dataset\n",
    "    dataset = MyDataset(train_data)\n",
    "\n",
    "    # Define the split ratio\n",
    "    train_ratio = 0.9  # 90% of the data for training, 10% for validation\n",
    "    train_size = int(train_ratio * len(dataset))\n",
    "    val_size = len(dataset) - train_size\n",
    "\n",
    "    # Split the dataset into training and validation sets\n",
    "    train_data_split, val_data_split = torch.utils.data.random_split(dataset, [train_size, val_size])\n",
    "\n",
    "    # Separate the columns into individual tensors for train and validation sets\n",
    "    Z_train = train_data_split.dataset.data[:train_size, 1].reshape(-1, 1)\n",
    "    X_train = train_data_split.dataset.data[:train_size, 2].reshape(-1, 1)\n",
    "    Y_train = train_data_split.dataset.data[:train_size, 3].reshape(-1, 1)\n",
    "\n",
    "    Z_val = val_data_split.dataset.data[train_size:, 1].reshape(-1, 1)\n",
    "    X_val = val_data_split.dataset.data[train_size:, 2].reshape(-1, 1)\n",
    "    Y_val = val_data_split.dataset.data[train_size:, 3].reshape(-1, 1)\n",
    "\n",
    "    # Define X_test and X_test_grid\n",
    "    X_test = torch.tensor(test_data[:, 0].astype(np.float32)).squeeze()\n",
    "    X_test_grid = torch.tensor(test_data[:, 4].astype(np.float32)).squeeze()\n",
    "\n",
    "    # Parallel execution of the training and prediction runs\n",
    "    results = Parallel(n_jobs=10)(\n",
    "        delayed(fit_predict_deepGMM)(run, X_train, Z_train, Y_train, X_val, Z_val, Y_val, X_test, X_test_grid)\n",
    "        for run in range(10)\n",
    "    )\n",
    "\n",
    "    # Initialize DataFrames for storing results\n",
    "    df_mse = pd.DataFrame()\n",
    "    df_plot = pd.DataFrame()\n",
    "\n",
    "    # Collect results from parallel execution\n",
    "    for run, (y_hat_deepGMM, y_hat_deepGMM_grid) in enumerate(results, start=1):\n",
    "        # Add the results as a new column to the DataFrame\n",
    "        df_mse[f'Run_{run}'] = y_hat_deepGMM\n",
    "        df_plot[f'Run_{run}'] = y_hat_deepGMM_grid\n",
    "\n",
    "    # Save the results to CSV files for the current dataset\n",
    "    df_mse.to_csv(f'results/sec5.1/deepgmm_result_mse_dgp{idx}.csv', index=False)\n",
    "    df_plot.to_csv(f'results/sec5.1/deepgmm_result_plot_dgp{idx}.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
